"""
å¿«é€Ÿæµ‹è¯•è„šæœ¬
éªŒè¯InfoViz-demoçš„åŸºæœ¬åŠŸèƒ½
"""

import os
import sys

def test_imports():
    """æµ‹è¯•æ¨¡å—å¯¼å…¥"""
    print("æµ‹è¯•æ¨¡å—å¯¼å…¥...")

    try:
        from text_processor import TextProcessor
        print("âœ“ TextProcessor å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âœ— TextProcessor å¯¼å…¥å¤±è´¥: {e}")
        return False

    try:
        from visualizer import DataVisualizer
        print("âœ“ DataVisualizer å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âœ— DataVisualizer å¯¼å…¥å¤±è´¥: {e}")
        return False

    try:
        from deepseek_client import DeepSeekClient
        print("âœ“ DeepSeekClient å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âœ— DeepSeekClient å¯¼å…¥å¤±è´¥: {e}")
        return False

    try:
        from main import InfoVizDemo
        print("âœ“ InfoVizDemo å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âœ— InfoVizDemo å¯¼å…¥å¤±è´¥: {e}")
        return False

    return True

def test_text_processing():
    """æµ‹è¯•æ–‡æœ¬å¤„ç†åŠŸèƒ½"""
    print("\næµ‹è¯•æ–‡æœ¬å¤„ç†åŠŸèƒ½...")

    try:
        from text_processor import TextProcessor

        processor = TextProcessor()
        sample_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ã€‚åŒ…å«ä¸€äº›æ•°å­—ï¼š123ï¼Œç™¾åˆ†æ¯”ï¼š50%ï¼Œä»¥åŠä¸€äº›å…³é”®è¯ã€‚"

        result = processor.create_data_summary(sample_text)

        print(f"âœ“ æ–‡æœ¬å¤„ç†æˆåŠŸ")
        print(f"  - æ–‡æœ¬é•¿åº¦: {result['basic_stats']['text_length']}")
        print(f"  - è¯æ•°: {result['basic_stats']['word_count']}")
        print(f"  - æ•°å­—æ•°é‡: {result['data_extraction']['numbers_found']}")
        print(f"  - ç™¾åˆ†æ¯”æ•°é‡: {result['data_extraction']['percentages_found']}")

        return True
    except Exception as e:
        print(f"âœ— æ–‡æœ¬å¤„ç†å¤±è´¥: {e}")
        return False

def test_visualization():
    """æµ‹è¯•å¯è§†åŒ–åŠŸèƒ½"""
    print("\næµ‹è¯•å¯è§†åŒ–åŠŸèƒ½...")

    try:
        from visualizer import DataVisualizer
        from text_processor import TextProcessor

        # åˆ›å»ºæµ‹è¯•æ•°æ®
        processor = TextProcessor()
        sample_text = "äººå·¥æ™ºèƒ½æŠ€æœ¯æ­£åœ¨å¿«é€Ÿå‘å±•ã€‚æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰æŠ€æœ¯ä¸æ–­çªç ´ã€‚"
        data_summary = processor.create_data_summary(sample_text)

        # åˆ›å»ºå¯è§†åŒ–å™¨
        visualizer = DataVisualizer(output_dir="test_output")

        # æµ‹è¯•è¯äº‘ç”Ÿæˆ
        wordcloud_path = visualizer.create_word_cloud(sample_text, "æµ‹è¯•è¯äº‘")
        print(f"âœ“ è¯äº‘ç”ŸæˆæˆåŠŸ: {wordcloud_path}")

        # æµ‹è¯•å…³é”®è¯é¢‘ç‡å›¾
        if data_summary['top_keywords']:
            keyword_path = visualizer.create_keyword_frequency_chart(data_summary['top_keywords'])
            print(f"âœ“ å…³é”®è¯é¢‘ç‡å›¾ç”ŸæˆæˆåŠŸ: {keyword_path}")

        return True
    except Exception as e:
        print(f"âœ— å¯è§†åŒ–æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_main_app():
    """æµ‹è¯•ä¸»ç¨‹åºåŠŸèƒ½"""
    print("\næµ‹è¯•ä¸»ç¨‹åºåŠŸèƒ½...")

    try:
        from main import InfoVizDemo

        # åˆ›å»ºæµ‹è¯•è¾“å‡ºç›®å½•
        test_output_dir = "test_output"
        if not os.path.exists(test_output_dir):
            os.makedirs(test_output_dir)

        # åˆå§‹åŒ–åº”ç”¨
        app = InfoVizDemo(output_dir=test_output_dir)

        # æµ‹è¯•æ–‡æœ¬
        sample_text = """
        2023å¹´ï¼Œä¸­å›½äººå·¥æ™ºèƒ½è¡Œä¸šå¿«é€Ÿå‘å±•ã€‚æ ¹æ®ç»Ÿè®¡æ•°æ®æ˜¾ç¤ºï¼Œ
        å…¨å›½AIä¼ä¸šæ•°é‡è¾¾åˆ°5000å¤šå®¶ï¼ŒåŒæ¯”å¢é•¿25%ã€‚
        åŒ—äº¬ã€ä¸Šæµ·ã€æ·±åœ³ç­‰ä¸€çº¿åŸå¸‚çš„AIä¼ä¸šæ•°é‡å å…¨å›½æ€»æ•°çš„60%ä»¥ä¸Šã€‚
        """

        # å¤„ç†æ–‡æœ¬ï¼ˆä¸ä½¿ç”¨DeepSeek APIï¼‰
        result = app.process_text(sample_text, use_deepseek=False)

        print("âœ“ ä¸»ç¨‹åºè¿è¡ŒæˆåŠŸ")
        print(f"  - ç”Ÿæˆäº† {len(result.get('visualizations', {}))} ä¸ªå¯è§†åŒ–æ–‡ä»¶")

        return True
    except Exception as e:
        print(f"âœ— ä¸»ç¨‹åºæµ‹è¯•å¤±è´¥: {e}")
        return False

def cleanup_test_files():
    """æ¸…ç†æµ‹è¯•æ–‡ä»¶"""
    print("\næ¸…ç†æµ‹è¯•æ–‡ä»¶...")

    import shutil

    test_dirs = ["test_output", "example_output"]
    for test_dir in test_dirs:
        if os.path.exists(test_dir):
            try:
                shutil.rmtree(test_dir)
                print(f"âœ“ æ¸…ç†ç›®å½•: {test_dir}")
            except Exception as e:
                print(f"âœ— æ¸…ç†ç›®å½•å¤±è´¥ {test_dir}: {e}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("InfoViz-demo åŠŸèƒ½æµ‹è¯•")
    print("=" * 40)

    tests = [
        test_imports,
        test_text_processing,
        test_visualization,
        test_main_app
    ]

    passed = 0
    total = len(tests)

    for test in tests:
        if test():
            passed += 1
        print()

    print("=" * 40)
    print(f"æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")

    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç¨‹åºå¯ä»¥æ­£å¸¸ä½¿ç”¨ã€‚")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¾èµ–åŒ…å®‰è£…ã€‚")

    # è¯¢é—®æ˜¯å¦æ¸…ç†æµ‹è¯•æ–‡ä»¶
    try:
        response = input("\næ˜¯å¦æ¸…ç†æµ‹è¯•æ–‡ä»¶ï¼Ÿ(y/n): ").lower().strip()
        if response in ['y', 'yes', 'æ˜¯']:
            cleanup_test_files()
    except KeyboardInterrupt:
        print("\næµ‹è¯•å®Œæˆã€‚")

if __name__ == "__main__":
    main()
