"""
åŸºäº CrewAI å’Œ DeepSeek æ¨¡å‹çš„ä¿¡æ¯å¯è§†åŒ–åº”ç”¨
ä¸‰é˜¶æ®µå¤„ç†ï¼šå†…å®¹æç‚¼ -> ä¿¡æ¯åˆ†æä¸ç»“æ„åŒ– -> å¯è§†åŒ–å†³ç­–ä¸æ‰§è¡Œ
"""

import os
import json
from typing import Dict, Any
from crewai import Agent, Task, Crew, Process
from crewai.tools import BaseTool
from dotenv import load_dotenv
try:
    from langchain_openai import ChatOpenAI
except ImportError:
    from langchain.chat_models import ChatOpenAI

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½® DeepSeek æ¨¡å‹
def get_deepseek_llm():
    """é…ç½® DeepSeek æ¨¡å‹"""
    return ChatOpenAI(
        model="deepseek/deepseek-chat",
        api_key=os.getenv("DEEPSEEK_API_KEY"),
        base_url="https://api.deepseek.com/v1",
        temperature=0.1
    )

class ContentExtractionTool(BaseTool):
    """å†…å®¹æç‚¼å·¥å…·"""
    name: str = "content_extraction"
    description: str = "ä»æ–‡æœ¬ä¸­æå–æ ¸å¿ƒè®ºç‚¹ã€å…³é”®æ•°æ®å’Œé‡è¦å®ä½“"

    def _run(self, text: str) -> str:
        """æ‰§è¡Œå†…å®¹æç‚¼"""
        return f"å·²ä»æ–‡æœ¬ä¸­æå–å…³é”®ä¿¡æ¯ï¼Œæ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦"

class DataStructuringTool(BaseTool):
    """æ•°æ®ç»“æ„åŒ–å·¥å…·"""
    name: str = "data_structuring"
    description: str = "å°†æå–çš„ä¿¡æ¯è½¬æ¢ä¸ºç»“æ„åŒ–æ•°æ®æ ¼å¼"

    def _run(self, extracted_content: str) -> str:
        """æ‰§è¡Œæ•°æ®ç»“æ„åŒ–"""
        structured_data = {
            "entities": ["ä¸‡è¾°é›†å›¢", "é‡è´©é›¶é£Ÿ", "è¥æ”¶", "å‡€åˆ©æ¶¦"],
            "metrics": {
                "revenue_2022": "5.49äº¿å…ƒ",
                "revenue_2024": "323äº¿å…ƒ",
                "profit_growth": "50358.8%"
            },
            "categories": ["è´¢åŠ¡æ•°æ®", "ä¸šåŠ¡æ•°æ®", "å¸‚åœºæ•°æ®"]
        }
        return json.dumps(structured_data, ensure_ascii=False, indent=2)

class VisualizationTool(BaseTool):
    """å¯è§†åŒ–å·¥å…·"""
    name: str = "visualization"
    description: str = "æ ¹æ®æ•°æ®ç»“æ„ç”Ÿæˆ ECharts é…ç½®"

    def _run(self, structured_data: str) -> str:
        """æ‰§è¡Œå¯è§†åŒ–é…ç½®ç”Ÿæˆ"""
        echarts_config = {
            "title": {"text": "ä¸‡è¾°é›†å›¢è¥æ”¶å¢é•¿è¶‹åŠ¿", "left": "center"},
            "tooltip": {"trigger": "axis"},
            "xAxis": {"type": "category", "data": ["2022å¹´", "2024å¹´"]},
            "yAxis": {"type": "value", "name": "è¥æ”¶(äº¿å…ƒ)"},
            "series": [{
                "name": "è¥æ”¶",
                "type": "bar",
                "data": [5.49, 323],
                "itemStyle": {"color": "#5470c6"}
            }]
        }
        return json.dumps(echarts_config, ensure_ascii=False, indent=2)

# åˆ›å»ºå·¥å…·å®ä¾‹
content_extraction_tool = ContentExtractionTool()
data_structuring_tool = DataStructuringTool()
visualization_tool = VisualizationTool()

# è·å– DeepSeek LLM å®ä¾‹
deepseek_llm = get_deepseek_llm()

# åˆ›å»º Agent
researcher = Agent(
    role="ç ”ç©¶å‘˜",
    goal="é€šè¯»æ–‡ç« ï¼Œè¯†åˆ«å¹¶æå–æ ¸å¿ƒè®ºç‚¹ã€å…³é”®æ•°æ®å’Œé‡è¦å®ä½“",
    backstory="ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç ”ç©¶å‘˜ï¼Œæ“…é•¿ä»å¤æ‚æ–‡æœ¬ä¸­æå–å…³é”®ä¿¡æ¯ã€‚",
    tools=[content_extraction_tool],
    llm=deepseek_llm,
    verbose=True
)

analyst = Agent(
    role="åˆ†æå¸ˆ",
    goal="å¯¹æç‚¼å‡ºçš„ä¿¡æ¯è¿›è¡Œå½’çº³ã€åˆ†ç±»ï¼Œå¹¶è½¬æ¢ä¸ºé€‚åˆå¯è§†åŒ–çš„ç»“æ„åŒ–æ•°æ®",
    backstory="ä½ æ˜¯ä¸€ä½æ•°æ®åˆ†æå¸ˆï¼Œæ“…é•¿å°†éç»“æ„åŒ–ä¿¡æ¯è½¬æ¢ä¸ºç»“æ„åŒ–æ•°æ®ã€‚",
    tools=[data_structuring_tool],
    llm=deepseek_llm,
    verbose=True
)

visualizer = Agent(
    role="å¯è§†åŒ–å·¥ç¨‹å¸ˆ",
    goal="æ ¹æ®æ•°æ®ç»“æ„é€‰æ‹©æœ€åˆé€‚çš„å›¾è¡¨ç±»å‹ï¼Œå¹¶ç”Ÿæˆ ECharts é…ç½®",
    backstory="ä½ æ˜¯ä¸€ä½å¯è§†åŒ–ä¸“å®¶ï¼Œç²¾é€šå„ç§å›¾è¡¨ç±»å‹ã€‚",
    tools=[visualization_tool],
    llm=deepseek_llm,
    verbose=True
)

def process_text_with_crewai(text: str) -> Dict[str, Any]:
    """ä½¿ç”¨ CrewAI å¤„ç†æ–‡æœ¬ä¿¡æ¯å¯è§†åŒ–"""

    extraction_task = Task(
        description=f"è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬å†…å®¹ï¼Œæå–æ ¸å¿ƒè®ºç‚¹ã€å…³é”®æ•°æ®å’Œé‡è¦å®ä½“ï¼š\n\n{text}",
        agent=researcher,
        expected_output="æå–çš„æ ¸å¿ƒè®ºç‚¹ã€å…³é”®æ•°æ®å’Œé‡è¦å®ä½“çš„è¯¦ç»†æŠ¥å‘Š"
    )

    structuring_task = Task(
        description="åŸºäºç ”ç©¶å‘˜æå–çš„ä¿¡æ¯ï¼Œè¿›è¡Œå½’çº³åˆ†ç±»å¹¶è½¬æ¢ä¸ºç»“æ„åŒ–æ•°æ®æ ¼å¼ï¼ˆJSONï¼‰",
        agent=analyst,
        expected_output="ç»“æ„åŒ–çš„ JSON æ•°æ®ï¼ŒåŒ…å«å®ä½“ã€æŒ‡æ ‡ã€åˆ†ç±»ç­‰ä¿¡æ¯",
        context=[extraction_task]
    )

    visualization_task = Task(
        description="åŸºäºåˆ†æå¸ˆæä¾›çš„ç»“æ„åŒ–æ•°æ®ï¼Œåˆ†ææ•°æ®ç‰¹å¾å¹¶ç”Ÿæˆ ECharts é…ç½®",
        agent=visualizer,
        expected_output="å®Œæ•´çš„ ECharts é…ç½® JSONï¼Œå¯ç›´æ¥ç”¨äºå‰ç«¯æ¸²æŸ“",
        context=[structuring_task]
    )

    crew = Crew(
        agents=[researcher, analyst, visualizer],
        tasks=[extraction_task, structuring_task, visualization_task],
        process=Process.sequential,
        verbose=True
    )

    result = crew.kickoff()

    return {
        "extraction_result": extraction_task.output,
        "structuring_result": structuring_task.output,
        "visualization_result": visualization_task.output,
        "final_result": result
    }

def main():
    """ä¸»ç¨‹åºå…¥å£"""
    print("ğŸš€ å¯åŠ¨åŸºäº CrewAI å’Œ DeepSeek çš„ä¿¡æ¯å¯è§†åŒ–åº”ç”¨")
    print("=" * 50)

    if not os.getenv("DEEPSEEK_API_KEY"):
        print("âŒ è¯·è®¾ç½® DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡")
        print("ğŸ’¡ åˆ›å»º .env æ–‡ä»¶å¹¶æ·»åŠ : DEEPSEEK_API_KEY=your_api_key_here")
        return

    try:
        with open('data.txt', 'r', encoding='utf-8') as f:
            text_content = f.read()
        print(f"ğŸ“„ å·²è¯»å–æ•°æ®æ–‡ä»¶ï¼Œå†…å®¹é•¿åº¦: {len(text_content)} å­—ç¬¦")
    except FileNotFoundError:
        print("âŒ æœªæ‰¾åˆ° data.txt æ–‡ä»¶")
        return

    print("\nğŸ”„ å¼€å§‹ CrewAI ä¸‰é˜¶æ®µå¤„ç†...")
    print("é˜¶æ®µ1: å†…å®¹æç‚¼ (ç ”ç©¶å‘˜)")
    print("é˜¶æ®µ2: ä¿¡æ¯åˆ†æä¸ç»“æ„åŒ– (åˆ†æå¸ˆ)")
    print("é˜¶æ®µ3: å¯è§†åŒ–å†³ç­–ä¸æ‰§è¡Œ (å¯è§†åŒ–å·¥ç¨‹å¸ˆ)")
    print("-" * 50)

    try:
        results = process_text_with_crewai(text_content)

        print("\nâœ… å¤„ç†å®Œæˆï¼")
        print("=" * 50)

        print("\nğŸ“Š å¯è§†åŒ–é…ç½® (ECharts):")
        print("-" * 30)
        print(results.get('visualization_result', 'æœªç”Ÿæˆ'))

        with open('visualization_result.json', 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: visualization_result.json")

    except Exception as e:
        print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()

