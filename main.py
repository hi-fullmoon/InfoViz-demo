"""
åŸºäº CrewAI å’Œ DeepSeek æ¨¡å‹çš„ä¿¡æ¯å¯è§†åŒ–åº”ç”¨
ä¸‰é˜¶æ®µå¤„ç†ï¼šå†…å®¹æç‚¼ -> ä¿¡æ¯åˆ†æä¸ç»“æ„åŒ– -> å¯è§†åŒ–å†³ç­–ä¸æ‰§è¡Œ
"""

import os
import json
from typing import Dict, Any
from crewai import Agent, Task, Crew, Process
from dotenv import load_dotenv
from tools import ContentExtractionTool, DataStructuringTool, VisualizationTool
try:
    from langchain_openai import ChatOpenAI
except ImportError:
    from langchain.chat_models import ChatOpenAI

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½® DeepSeek æ¨¡å‹
def get_deepseek_llm():
    """é…ç½® DeepSeek æ¨¡å‹"""
    return ChatOpenAI(
        model="deepseek/deepseek-chat",
        api_key=os.getenv("DEEPSEEK_API_KEY"),
        base_url="https://api.deepseek.com/v1",
        temperature=0.1
    )


# åˆ›å»ºå·¥å…·å®ä¾‹
content_extraction_tool = ContentExtractionTool()
data_structuring_tool = DataStructuringTool()
visualization_tool = VisualizationTool()

# è·å– DeepSeek LLM å®ä¾‹
deepseek_llm = get_deepseek_llm()

# åˆ›å»º Agent
researcher = Agent(
    role="ç ”ç©¶å‘˜",
    goal="é€šè¯»æ–‡ç« ï¼Œè¯†åˆ«å¹¶æå–æ ¸å¿ƒè®ºç‚¹ã€å…³é”®æ•°æ®å’Œé‡è¦å®ä½“",
    backstory="ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç ”ç©¶å‘˜ï¼Œæ“…é•¿ä»å¤æ‚æ–‡æœ¬ä¸­æå–å…³é”®ä¿¡æ¯ã€‚",
    tools=[content_extraction_tool],
    llm=deepseek_llm,
    verbose=True
)

analyst = Agent(
    role="åˆ†æå¸ˆ",
    goal="å¯¹æç‚¼å‡ºçš„ä¿¡æ¯è¿›è¡Œå½’çº³ã€åˆ†ç±»ï¼Œå¹¶è½¬æ¢ä¸ºé€‚åˆå¯è§†åŒ–çš„ç»“æ„åŒ–æ•°æ®",
    backstory="ä½ æ˜¯ä¸€ä½æ•°æ®åˆ†æå¸ˆï¼Œæ“…é•¿å°†éç»“æ„åŒ–ä¿¡æ¯è½¬æ¢ä¸ºç»“æ„åŒ–æ•°æ®ã€‚",
    tools=[data_structuring_tool],
    llm=deepseek_llm,
    verbose=True
)

visualizer = Agent(
    role="å¯è§†åŒ–å·¥ç¨‹å¸ˆ",
    goal="æ ¹æ®æ•°æ®ç»“æ„æ™ºèƒ½é€‰æ‹©å¤šä¸ªæœ€åˆé€‚çš„å›¾è¡¨ç±»å‹ï¼Œç”Ÿæˆå¤šä¸ª ECharts é…ç½®ï¼Œç¡®ä¿æ•°æ®æ•…äº‹å®Œæ•´æ€§å’Œå¯è§†åŒ–æ•ˆæœæœ€ä½³",
    backstory="ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æ•°æ®å¯è§†åŒ–ä¸“å®¶ï¼Œç²¾é€šå„ç§å›¾è¡¨ç±»å‹å’Œå¯è§†åŒ–æœ€ä½³å®è·µã€‚ä½ èƒ½å¤Ÿï¼š\n"
              "1. åˆ†ææ•°æ®ç‰¹å¾ï¼Œè¯†åˆ«å…³é”®æ´å¯Ÿç‚¹\n"
              "2. é€‰æ‹©æœ€é€‚åˆçš„å›¾è¡¨ç±»å‹ç»„åˆæ¥è®²è¿°æ•°æ®æ•…äº‹\n"
              "3. ç”Ÿæˆå¤šä¸ªç‹¬ç«‹çš„EChartsé…ç½®ï¼Œæ¯ä¸ªå›¾è¡¨éƒ½æœ‰æ˜ç¡®çš„åˆ†æç›®æ ‡\n"
              "4. ç¡®ä¿å›¾è¡¨é—´çš„é€»è¾‘å…³è”æ€§å’Œè§†è§‰ä¸€è‡´æ€§\n"
              "5. è€ƒè™‘ç”¨æˆ·äº¤äº’ä½“éªŒå’Œå›¾è¡¨å¯è¯»æ€§",
    tools=[visualization_tool],
    llm=deepseek_llm,
    verbose=True
)

def process_text_with_crewai(text: str) -> Dict[str, Any]:
    """ä½¿ç”¨ CrewAI å¤„ç†æ–‡æœ¬ä¿¡æ¯å¯è§†åŒ–"""

    extraction_task = Task(
        description=f"è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬å†…å®¹ï¼Œæå–æ ¸å¿ƒè®ºç‚¹ã€å…³é”®æ•°æ®å’Œé‡è¦å®ä½“ï¼š\n\n{text}",
        agent=researcher,
        expected_output="æå–çš„æ ¸å¿ƒè®ºç‚¹ã€å…³é”®æ•°æ®å’Œé‡è¦å®ä½“çš„è¯¦ç»†æŠ¥å‘Š"
    )

    structuring_task = Task(
        description="åŸºäºç ”ç©¶å‘˜æå–çš„ä¿¡æ¯ï¼Œè¿›è¡Œå½’çº³åˆ†ç±»å¹¶è½¬æ¢ä¸ºç»“æ„åŒ–æ•°æ®æ ¼å¼ï¼ˆJSONï¼‰",
        agent=analyst,
        expected_output="ç»“æ„åŒ–çš„ JSON æ•°æ®ï¼ŒåŒ…å«å®ä½“ã€æŒ‡æ ‡ã€åˆ†ç±»ç­‰ä¿¡æ¯",
        context=[extraction_task]
    )

    visualization_task = Task(
        description="åŸºäºåˆ†æå¸ˆæä¾›çš„ç»“æ„åŒ–æ•°æ®ï¼Œè¿›è¡Œæ·±åº¦åˆ†æå¹¶ç”Ÿæˆå¤šä¸ª ECharts å›¾è¡¨é…ç½®ã€‚\n"
                   "è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ‰§è¡Œï¼š\n"
                   "1. åˆ†ææ•°æ®ç»“æ„ï¼Œè¯†åˆ«å…³é”®æ•°æ®ç»´åº¦å’Œå…³ç³»\n"
                   "2. ç¡®å®šéœ€è¦å¤šå°‘ä¸ªå›¾è¡¨æ¥å®Œæ•´å±•ç¤ºæ•°æ®æ•…äº‹\n"
                   "3. ä¸ºæ¯ä¸ªå›¾è¡¨é€‰æ‹©æœ€é€‚åˆçš„ç±»å‹ï¼ˆæŸ±çŠ¶å›¾ã€æŠ˜çº¿å›¾ã€é¥¼å›¾ã€æ•£ç‚¹å›¾ç­‰ï¼‰\n"
                   "4. ç¡®ä¿å›¾è¡¨é—´æœ‰é€»è¾‘å…³è”ï¼Œå½¢æˆå®Œæ•´çš„æ•°æ®åˆ†ææŠ¥å‘Š\n"
                   "5. ç”Ÿæˆå¤šä¸ªç‹¬ç«‹çš„EChartsé…ç½®ï¼Œæ¯ä¸ªé…ç½®éƒ½åº”è¯¥æ˜¯å®Œæ•´å¯ç”¨çš„\n"
                   "6. è€ƒè™‘å›¾è¡¨çš„è§†è§‰ä¸€è‡´æ€§å’Œç”¨æˆ·ä½“éªŒ",
        agent=visualizer,
        expected_output="åŒ…å«å¤šä¸ªEChartså›¾è¡¨é…ç½®çš„JSONå¯¹è±¡ï¼Œæ¯ä¸ªå›¾è¡¨éƒ½æœ‰ï¼š\n"
                       "- chart_id: å›¾è¡¨å”¯ä¸€æ ‡è¯†\n"
                       "- title: å›¾è¡¨æ ‡é¢˜\n"
                       "- type: å›¾è¡¨ç±»å‹\n"
                       "- config: å®Œæ•´çš„EChartsé…ç½®\n"
                       "åŒæ—¶åŒ…å«å¸ƒå±€ä¿¡æ¯å’Œå›¾è¡¨æ€»æ•°",
        context=[structuring_task]
    )

    crew = Crew(
        agents=[researcher, analyst, visualizer],
        tasks=[extraction_task, structuring_task, visualization_task],
        process=Process.sequential,
        verbose=True
    )

    result = crew.kickoff()

    return {
        "extraction_result": str(extraction_task.output) if extraction_task.output else "æœªå®Œæˆ",
        "structuring_result": str(structuring_task.output) if structuring_task.output else "æœªå®Œæˆ",
        "visualization_result": str(visualization_task.output) if visualization_task.output else "æœªå®Œæˆ",
        "final_result": str(result) if result else "æœªå®Œæˆ"
    }

def main():
    """ä¸»ç¨‹åºå…¥å£"""
    print("ğŸš€ å¯åŠ¨åŸºäº CrewAI å’Œ DeepSeek çš„ä¿¡æ¯å¯è§†åŒ–åº”ç”¨")
    print("=" * 50)

    if not os.getenv("DEEPSEEK_API_KEY"):
        print("âŒ è¯·è®¾ç½® DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡")
        print("ğŸ’¡ åˆ›å»º .env æ–‡ä»¶å¹¶æ·»åŠ : DEEPSEEK_API_KEY=your_api_key_here")
        return

    try:
        with open('data.txt', 'r', encoding='utf-8') as f:
            text_content = f.read()
        print(f"ğŸ“„ å·²è¯»å–æ•°æ®æ–‡ä»¶ï¼Œå†…å®¹é•¿åº¦: {len(text_content)} å­—ç¬¦")
    except FileNotFoundError:
        print("âŒ æœªæ‰¾åˆ° data.txt æ–‡ä»¶")
        return

    print("\nğŸ”„ å¼€å§‹ CrewAI ä¸‰é˜¶æ®µå¤„ç†...")
    print("é˜¶æ®µ1: å†…å®¹æç‚¼ (ç ”ç©¶å‘˜)")
    print("é˜¶æ®µ2: ä¿¡æ¯åˆ†æä¸ç»“æ„åŒ– (åˆ†æå¸ˆ)")
    print("é˜¶æ®µ3: å¯è§†åŒ–å†³ç­–ä¸æ‰§è¡Œ (å¯è§†åŒ–å·¥ç¨‹å¸ˆ)")
    print("-" * 50)

    try:
        results = process_text_with_crewai(text_content)

        print("\nâœ… å¤„ç†å®Œæˆï¼")

        # ç¡®ä¿æ‰€æœ‰ç»“æœéƒ½æ˜¯å­—ç¬¦ä¸²æ ¼å¼
        serializable_results = {
            "extraction_result": str(results.get('extraction_result', 'æœªå®Œæˆ')),
            "structuring_result": str(results.get('structuring_result', 'æœªå®Œæˆ')),
            "visualization_result": str(results.get('visualization_result', 'æœªå®Œæˆ')),
            "final_result": str(results.get('final_result', 'æœªå®Œæˆ')),
            "timestamp": str(__import__('datetime').datetime.now())
        }

        with open('visualization_result.json', 'w', encoding='utf-8') as f:
            json.dump(serializable_results, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: visualization_result.json")

    except Exception as e:
        print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()

